# -*- coding: utf-8 -*-
"""project_nti_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BmrSesHPgd0J4QOcts9Cfz9Z_KxL9h-d
"""

# This notebook contains the final implementation of the Hospital Gesture Recognition System

#import kagglehub

# Download latest version
#path = kagglehub.dataset_download("innominate817/hagrid-sample-30k-384p")

#print("Path to dataset files:", path)


# ===== 1. افحص المسار =====
import os

print(f" Base path: {path}")
print(f"\n Contents:")

# اطبع كل اللي جوه المسار
for item in os.listdir(path):
    item_path = os.path.join(path, item)
    if os.path.isdir(item_path):
        print(f"   {item}/")
        # اطبع اللي جواه
        sub_items = os.listdir(item_path)[:5]  # أول 5 بس
        for sub in sub_items:
            print(f"      - {sub}")
    else:
        print(f"   {item}")

#  السطر ده الأول علشان تتأكد من المسار:
import os
base_path = "/root/.cache/kagglehub/datasets/innominate817/hagrid-sample-30k-384p/versions/5"
print(" Contents:", os.listdir(base_path))

# HOSPITAL GESTURE RECOGNITION MODEL - FIXED VERSION
# Dataset: HaGRID Sample 30k-384p
# ============================================================================
# 1. IMPORTS
import os
import shutil
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (GlobalAveragePooling2D, Dense,
                                     Dropout, BatchNormalization, Activation)
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Set seed for reproducibility
tf.random.set_seed(42)
np.random.seed(42)

# ============================================================================
# 2. DATASET PREPARATION - FIXING THE STRUCTURE
# ============================================================================

def prepare_dataset_structure(source_path, dest_path, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    تقسيم الداتاسيت بشكل صحيح إلى train/val/test
    بدل استخدام validation_split اللي بيعمل data leakage
    """
    print("="*80)
    print(" PREPARING DATASET STRUCTURE")
    print("="*80)

    # The actual dataset is inside 'hagrid-sample-30k-384p' which contains 'hagrid_30k'
    hagrid_path = os.path.join(source_path, "hagrid-sample-30k-384p", "hagrid_30k")

    if not os.path.exists(hagrid_path):
        raise ValueError(f" Path not found: {hagrid_path}\nPlease check your dataset path!")

    #
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(dest_path, split), exist_ok=True)

    #
    classes = [d for d in os.listdir(hagrid_path)
               if os.path.isdir(os.path.join(hagrid_path, d))]

    print(f"\n Found {len(classes)} classes: {classes}\n")

    total_images = 0
    class_distribution = {'train': {}, 'val': {}, 'test': {}}

    for class_name in classes:
        class_path = os.path.join(hagrid_path, class_name)
        images = [f for f in os.listdir(class_path)
                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

        if len(images) == 0:
            print(f"  Warning: No images found in class '{class_name}'")
            continue

        #
        train_imgs, temp_imgs = train_test_split(images, train_size=train_ratio, random_state=42)
        val_imgs, test_imgs = train_test_split(temp_imgs, train_size=val_ratio/(val_ratio+test_ratio), random_state=42)

        #
        for split, img_list in [('train', train_imgs), ('val', val_imgs), ('test', test_imgs)]:
            split_class_path = os.path.join(dest_path, split, class_name)
            os.makedirs(split_class_path, exist_ok=True)

            for img in img_list:
                src = os.path.join(class_path, img)
                dst = os.path.join(split_class_path, img)
                shutil.copy2(src, dst)

            class_distribution[split][class_name] = len(img_list)

        total_images += len(images)
        print(f" {class_name}: {len(train_imgs)} train | {len(val_imgs)} val | {len(test_imgs)} test")

    print(f"\n Total images processed: {total_images}")
    print(f" Dataset saved to: {dest_path}")

    return class_distribution


# ============================================================================
# 3. CONFIGURATION
# ============================================================================

# مسارات الداتاسيت
ORIGINAL_DATA_PATH = "/root/.cache/kagglehub/datasets/innominate817/hagrid-sample-30k-384p/versions/5"
PROCESSED_DATA_PATH = "/content/gesture_dataset_split"

# إعدادات الموديل
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 30
INITIAL_LR = 0.0001  #  قللنا الـ LR (كان 0.001)

#  Fine-tuning من البداية - CRITICAL FIX!
UNFREEZE_FROM_START = True  #  غيرناها لـ True

# ============================================================================
# 4. PREPARE DATASET (RUN ONCE)
# ============================================================================

#  السطر ده   لتقسيم الداتاسيت
if not os.path.exists(PROCESSED_DATA_PATH):
    class_dist = prepare_dataset_structure(
        source_path=ORIGINAL_DATA_PATH,
        dest_path=PROCESSED_DATA_PATH,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15
    )
else:
    print(" Dataset already prepared!")

# ============================================================================
# 5. DATA GENERATORS - WITHOUT VALIDATION_SPLIT
# ============================================================================

print("\n" + "="*80)
print(" CREATING DATA GENERATORS")
print("="*80)

# Augmentation أخف - CRITICAL FIX!
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,        #  قللنا من 15
    width_shift_range=0.1,    #  قللنا من 0.15
    height_shift_range=0.1,   #  قللنا من 0.15
    shear_range=0.05,         #  قللنا من 0.1
    zoom_range=0.05,          #  قللنا من 0.1
    horizontal_flip=True,
    fill_mode='nearest'
)

# للـ validation و test بدون augmentation
val_test_datagen = ImageDataGenerator(rescale=1./255)

# إنشاء الـ generators
train_generator = train_datagen.flow_from_directory(
    os.path.join(PROCESSED_DATA_PATH, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True,
    seed=42
)

val_generator = val_test_datagen.flow_from_directory(
    os.path.join(PROCESSED_DATA_PATH, 'val'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_generator = val_test_datagen.flow_from_directory(
    os.path.join(PROCESSED_DATA_PATH, 'test'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

print(f"\n Number of classes: {train_generator.num_classes}")
print(f" Training samples: {train_generator.samples}")
print(f" Validation samples: {val_generator.samples}")
print(f" Test samples: {test_generator.samples}")
print(f"\n  Class labels: {list(train_generator.class_indices.keys())}")

# ============================================================================
# 6. BUILD MODEL
# ============================================================================

print("\n" + "="*80)
print("  BUILDING MODEL")
print("="*80)

base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(*IMG_SIZE, 3)
)

# تجميد الـ base model
if UNFREEZE_FROM_START:
    base_model.trainable = True
    # فك تجميد آخر 50 layer بس
    for layer in base_model.layers[:-50]:
        layer.trainable = False
    print(" Fine-tuning mode: Last 50 layers unfrozen from start")
else:
    base_model.trainable = False
    print(" Transfer learning mode: Base model frozen initially")

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),


    Dense(512, kernel_regularizer=l2(0.0001)),  # زودنا neurons
    BatchNormalization(),
    Activation('relu'),
    Dropout(0.4),  # قللنا dropout

    Dense(256, kernel_regularizer=l2(0.0001)),
    BatchNormalization(),
    Activation('relu'),
    Dropout(0.4),

    Dense(train_generator.num_classes, activation='softmax')
])

model.compile(
    optimizer=Adam(learning_rate=INITIAL_LR),  # 0.0001 بدل 0.001
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\n MODEL SUMMARY:")
model.summary()

# ============================================================================
# 7. CALLBACKS
# ============================================================================

callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=7,
        restore_best_weights=True,
        verbose=1
    ),

    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    ),

    ModelCheckpoint(
        'best_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    )
]

# ============================================================================
# 8. TRAINING - SINGLE PHASE WITH FINE-TUNING
# ============================================================================

print("\n" + "="*80)
print(" TRAINING WITH FINE-TUNING FROM START")
print("="*80)

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# ============================================================================
# 10. EVALUATION
# ============================================================================

print("\n" + "="*80)
print(" FINAL EVALUATION")
print("="*80)

train_acc = history.history['accuracy'][-1] * 100
val_acc = history.history['val_accuracy'][-1] * 100
train_loss = history.history['loss'][-1]
val_loss = history.history['val_loss'][-1]

print(f" Train Accuracy: {train_acc:.2f}%")
print(f" Val Accuracy: {val_acc:.2f}%")
print(f" Train Loss: {train_loss:.4f}")
print(f" Val Loss: {val_loss:.4f}")

gap = train_acc - val_acc
print(f"\n Overfitting Gap: {gap:.2f}%")
if gap < 5:
    print("    Excellent! Low overfitting")
elif gap < 10:
    print("     Moderate overfitting")
else:
    print("    High overfitting - consider more regularization")

# Test set evaluation
print("\n" + "="*80)
print(" TEST SET EVALUATION")
print("="*80)

test_loss, test_acc = model.evaluate(test_generator, verbose=0)
print(f" Test Accuracy: {test_acc*100:.2f}%")
print(f" Test Loss: {test_loss:.4f}")

# ============================================================================
# 11. VISUALIZATION
# ============================================================================

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Accuracy plot
axes[0].plot(history.history['accuracy'], 'b-', label='Train Acc', linewidth=2.5)
axes[0].plot(history.history['val_accuracy'], 'r-', label='Val Acc', linewidth=2.5)
axes[0].axhline(y=0.90, color='green', linestyle='--', linewidth=2, label='Target (90%)')
axes[0].set_title('Model Accuracy', fontsize=16, fontweight='bold')
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Accuracy', fontsize=12)
axes[0].legend(fontsize=11)
axes[0].grid(True, alpha=0.3)

# Loss plot
axes[1].plot(history.history['loss'], 'b-', label='Train Loss', linewidth=2.5)
axes[1].plot(history.history['val_loss'], 'r-', label='Val Loss', linewidth=2.5)
axes[1].set_title('Model Loss', fontsize=16, fontweight='bold')
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Loss', fontsize=12)
axes[1].legend(fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n Plot saved as 'training_results.png'")

# ============================================================================
# 12. SAVE MODEL & CLASS NAMES
# ============================================================================

print("\n" + "="*80)
print(" SAVING MODEL")
print("="*80)

model.save('hospital_gesture_model_final.keras')
print(" Model saved as 'hospital_gesture_model_final.keras'")

# Save class names
class_names = list(train_generator.class_indices.keys())
with open('class_names.json', 'w') as f:
    json.dump(class_names, f, indent=2)
print(" Class names saved as 'class_names.json'")

print("\n" + "="*80)
print(" ALL DONE!")
print("="*80)

# ============================================================================
# 13. DETAILED MODEL EVALUATION
# ============================================================================

print("\n" + "="*80)
print(" DETAILED MODEL EVALUATION")
print("="*80)

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Get predictions on test set
print("\n Generating predictions on test set...")
test_generator.reset()  # Important: reset generator before prediction
test_preds = model.predict(test_generator, verbose=1)
test_pred_classes = np.argmax(test_preds, axis=1)
test_true_classes = test_generator.classes

# Get class names
class_names = list(test_generator.class_indices.keys())

# ============================================================================
# Classification Report
# ============================================================================
print("\n" + "="*80)
print(" CLASSIFICATION REPORT")
print("="*80)
print(classification_report(
    test_true_classes,
    test_pred_classes,
    target_names=class_names,
    digits=3
))

# ============================================================================
# Confusion Matrix
# ============================================================================
print("\n Generating confusion matrix...")
cm = confusion_matrix(test_true_classes, test_pred_classes)

plt.figure(figsize=(16, 14))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={'label': 'Count'})
plt.title('Confusion Matrix - Test Set', fontsize=18, fontweight='bold', pad=20)
plt.ylabel('True Label', fontsize=14, fontweight='bold')
plt.xlabel('Predicted Label', fontsize=14, fontweight='bold')
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(rotation=0, fontsize=10)
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()
print(" Confusion matrix saved as 'confusion_matrix.png'")

# ============================================================================
# Per-Class Accuracy Analysis
# ============================================================================
print("\n" + "="*80)
print(" PER-CLASS ACCURACY ANALYSIS")
print("="*80)

class_accuracy = cm.diagonal() / cm.sum(axis=1)
avg_accuracy = np.mean(class_accuracy)

# Sort by accuracy for better visualization
sorted_indices = np.argsort(class_accuracy)

print(f"\n Average Per-Class Accuracy: {avg_accuracy*100:.2f}%\n")
print("-" * 70)

for idx in sorted_indices:
    acc = class_accuracy[idx]
    class_name = class_names[idx]

    # Status based on accuracy
    if acc >= 0.85:
        status = "✓ EXCELLENT"
        color_code = "\033[92m"  # Green
    elif acc >= 0.70:
        status = "⚠ ACCEPTABLE"
        color_code = "\033[93m"  # Yellow
    else:
        status = "✗ NEEDS REVIEW"
        color_code = "\033[91m"  # Red

    reset_code = "\033[0m"

    # Print with bar chart
    bar_length = int(acc * 40)
    bar = "█" * bar_length + "░" * (40 - bar_length)

    print(f"{color_code}{status}{reset_code} {class_name:25s}: {acc*100:5.1f}% {bar}")

print("-" * 70)

# ============================================================================
# Per-Class Accuracy Visualization
# ============================================================================
print("\n Generating per-class accuracy chart...")

fig, ax = plt.subplots(figsize=(14, 10))

colors = ['#d32f2f' if acc < 0.70 else '#ff9800' if acc < 0.85 else '#4caf50'
          for acc in class_accuracy[sorted_indices]]

bars = ax.barh(range(len(class_names)),
               class_accuracy[sorted_indices] * 100,
               color=colors,
               edgecolor='black',
               linewidth=1.5)

# Add value labels on bars
for i, (bar, acc) in enumerate(zip(bars, class_accuracy[sorted_indices])):
    width = bar.get_width()
    ax.text(width + 1, bar.get_y() + bar.get_height()/2,
            f'{acc*100:.1f}%',
            ha='left', va='center', fontweight='bold', fontsize=10)

ax.set_yticks(range(len(class_names)))
ax.set_yticklabels([class_names[i] for i in sorted_indices], fontsize=11)
ax.set_xlabel('Accuracy (%)', fontsize=13, fontweight='bold')
ax.set_title('Per-Class Accuracy on Test Set', fontsize=16, fontweight='bold', pad=20)
ax.set_xlim(0, 105)
ax.grid(axis='x', alpha=0.3, linestyle='--')

# Add reference lines
ax.axvline(x=85, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Excellent (85%)')
ax.axvline(x=70, color='orange', linestyle='--', linewidth=2, alpha=0.5, label='Acceptable (70%)')
ax.legend(loc='lower right', fontsize=10)

plt.tight_layout()
plt.savefig('per_class_accuracy.png', dpi=300, bbox_inches='tight')
plt.show()
print(" Per-class accuracy chart saved as 'per_class_accuracy.png'")

# ============================================================================
# Classes Needing Review
# ============================================================================
weak_classes = [(class_names[i], class_accuracy[i])
                for i in range(len(class_names)) if class_accuracy[i] < 0.70]

if weak_classes:
    print("\n" + "="*80)
    print(" CLASSES NEEDING REVIEW (< 70% accuracy)")
    print("="*80)
    for class_name, acc in sorted(weak_classes, key=lambda x: x[1]):
        print(f"  • {class_name:25s}: {acc*100:.1f}%")
    print("\n Recommendations:")
    print("  1. Collect more training samples for these classes")
    print("  2. Review data quality and labeling")
    print("  3. Consider class-weighted loss function")
else:
    print("\n" + "="*80)
    print("  ALL CLASSES ACHIEVE ≥70% ACCURACY!")
    print("="*80)

# ============================================================================
# Summary Statistics
# ============================================================================
print("\n" + "="*80)
print(" SUMMARY STATISTICS")
print("="*80)
print(f"  Total Test Samples: {len(test_true_classes)}")
print(f"  Correct Predictions: {np.sum(test_pred_classes == test_true_classes)}")
print(f"  Overall Test Accuracy: {test_acc*100:.2f}%")
print(f"  Average Per-Class Accuracy: {avg_accuracy*100:.2f}%")
print(f"  Best Class: {class_names[np.argmax(class_accuracy)]} ({np.max(class_accuracy)*100:.1f}%)")
print(f"  Worst Class: {class_names[np.argmin(class_accuracy)]} ({np.min(class_accuracy)*100:.1f}%)")
print("="*80)

print("\n Evaluation complete!")

# Medical Gesture Mapping Configuration

import json
import os

print("\n" + "="*80)
print(" CREATING MEDICAL GESTURE MAPPING")
print("="*80)

# Create config directory if it doesn't exist
os.makedirs('config', exist_ok=True)

MEDICAL_GESTURE_MAP = {
    # Navigation & Control
    "swipe_right": {
        "action": "next_image",
        "description": "Navigate to next X-ray/scan image",
        "medical_use": "Review next medical image",
        "icon": "ARROW_RIGHT",
        "priority": "high"
    },
    "swipe_left": {
        "action": "previous_image",
        "description": "Navigate to previous X-ray/scan image",
        "medical_use": "Review previous medical image",
        "icon": "ARROW_LEFT",
        "priority": "high"
    },
    "swipe_up": {
        "action": "zoom_in",
        "description": "Zoom in on medical image",
        "medical_use": "Examine details in X-ray/CT scan",
        "icon": "ZOOM_IN",
        "priority": "medium"
    },
    "swipe_down": {
        "action": "zoom_out",
        "description": "Zoom out from medical image",
        "medical_use": "See full view of scan",
        "icon": "ZOOM_OUT",
        "priority": "medium"
    },

    # Emergency & Alerts
    "palm": {
        "action": "emergency_stop",
        "description": "STOP - Pause current operation",
        "medical_use": "Emergency halt during procedure",
        "icon": "STOP",
        "priority": "critical",
        "alert_level": "red"
    },
    "fist": {
        "action": "call_nurse",
        "description": "Call nurse immediately",
        "medical_use": "Patient needs assistance",
        "icon": "ALERT",
        "priority": "critical",
        "alert_level": "orange"
    },

    # Confirmation & Selection
    "thumb_up": {
        "action": "confirm",
        "description": "Confirm/Accept action",
        "medical_use": "Approve medication, confirm diagnosis",
        "icon": "CONFIRM",
        "priority": "high"
    },
    "thumb_down": {
        "action": "reject",
        "description": "Reject/Cancel action",
        "medical_use": "Decline medication, cancel operation",
        "icon": "REJECT",
        "priority": "high"
    },

    # Patient Communication
    "ok": {
        "action": "im_okay",
        "description": "Patient indicates they're okay",
        "medical_use": "Quick status check response",
        "icon": "STATUS_OK",
        "priority": "medium"
    },
    "peace": {
        "action": "need_help",
        "description": "Patient needs help (non-emergency)",
        "medical_use": "Request assistance, water, bathroom",
        "icon": "HELP_REQUEST",
        "priority": "medium"
    },

    # Pain Level Indicators
    "one": {
        "action": "pain_level_1",
        "description": "Mild pain (1/10)",
        "medical_use": "Indicate pain level",
        "icon": "PAIN_1",
        "priority": "medium"
    },
    "two": {
        "action": "pain_level_2",
        "description": "Moderate pain (2/10)",
        "medical_use": "Indicate pain level",
        "icon": "PAIN_2",
        "priority": "medium"
    },
    "three": {
        "action": "pain_level_3",
        "description": "Significant pain (3/10)",
        "medical_use": "Indicate pain level",
        "icon": "PAIN_3",
        "priority": "medium"
    },
    "four": {
        "action": "pain_level_4",
        "description": "High pain (4/10)",
        "medical_use": "Indicate pain level",
        "icon": "PAIN_4",
        "priority": "high"
    },
    "five": {
        "action": "pain_level_5",
        "description": "Severe pain (5/10)",
        "medical_use": "Indicate pain level - needs attention",
        "icon": "PAIN_5",
        "priority": "high"
    },

    # Medical Imaging Controls
    "pointer": {
        "action": "mark_region",
        "description": "Point to/mark region of interest",
        "medical_use": "Indicate area of concern in scan",
        "icon": "POINTER",
        "priority": "medium"
    },

    # System Navigation
    "call": {
        "action": "open_menu",
        "description": "Open system menu",
        "medical_use": "Access patient records, medications",
        "icon": "MENU",
        "priority": "low"
    },

    # Additional gestures based on your dataset
    "rock": {
        "action": "lock_screen",
        "description": "Lock/secure screen",
        "medical_use": "Privacy protection",
        "icon": "LOCK",
        "priority": "low"
    },
    "dislike": {
        "action": "report_issue",
        "description": "Report problem/side effect",
        "medical_use": "Indicate adverse reaction",
        "icon": "WARNING",
        "priority": "high"
    },
    "like": {
        "action": "feeling_better",
        "description": "Indicate improvement",
        "medical_use": "Positive response to treatment",
        "icon": "IMPROVEMENT",
        "priority": "medium"
    }
}

# Save mapping to JSON file
mapping_path = 'config/medical_gesture_mapping.json'
with open(mapping_path, 'w', encoding='utf-8') as f:
    json.dump(MEDICAL_GESTURE_MAP, f, indent=2, ensure_ascii=False)

print(f"\n ✓ Medical gesture mapping created!")
print(f" ✓ Total gestures mapped: {len(MEDICAL_GESTURE_MAP)}")
print(f" ✓ Saved to: {mapping_path}")

# Display mapping summary
print("\n" + "="*80)
print(" GESTURE MAPPING SUMMARY")
print("="*80)

priority_count = {}
for gesture, info in MEDICAL_GESTURE_MAP.items():
    priority = info['priority']
    priority_count[priority] = priority_count.get(priority, 0) + 1

print(f"\n Gestures by priority:")
for priority in ['critical', 'high', 'medium', 'low']:
    count = priority_count.get(priority, 0)
    if count > 0:
        print(f"   {priority.upper():10s}: {count} gestures")

print("\n" + "="*80)

# ============================================================================
# GESTURE ACTION HANDLER
# ============================================================================

import json
import time
from datetime import datetime
from typing import Dict, Any, Optional, List

print("\n" + "="*80)
print(" CREATING GESTURE ACTION HANDLER")
print("="*80)

class GestureActionHandler:
    """
    Handles gesture-to-action mapping for hospital system
    """

    def __init__(self, mapping_file='config/medical_gesture_mapping.json'):
        """Initialize handler with gesture mapping"""
        try:
            with open(mapping_file, 'r', encoding='utf-8') as f:
                self.gesture_map = json.load(f)
            print(f" ✓ Loaded {len(self.gesture_map)} gesture mappings")
        except FileNotFoundError:
            print(f" ✗ Error: Mapping file not found: {mapping_file}")
            print(" Please run the Medical Gesture Mapping script first!")
            raise

        self.action_history = []
        self.last_action_time = None
        self.debounce_time = 1.0  # seconds between actions

    def get_action(self, gesture: str, confidence: float) -> Optional[Dict[str, Any]]:
        """
        Get action for gesture with confidence threshold

        Args:
            gesture: Gesture name (e.g., 'train_val_palm')
            confidence: Prediction confidence (0-1)

        Returns:
            Dictionary with action details or rejection reason
        """
        # Confidence thresholds based on priority
        thresholds = {
            'critical': 0.85,  # Emergency actions need high confidence
            'high': 0.75,
            'medium': 0.65,
            'low': 0.55
        }

        # Check if gesture exists in mapping
        if gesture not in self.gesture_map:
            return {
                'status': 'unknown',
                'reason': f'Gesture "{gesture}" not in mapping',
                'gesture': gesture,
                'confidence': confidence
            }

        gesture_info = self.gesture_map[gesture]
        required_confidence = thresholds.get(gesture_info['priority'], 0.70)

        # Check confidence threshold
        if confidence < required_confidence:
            return {
                'status': 'rejected',
                'reason': f'Confidence {confidence:.2f} below threshold {required_confidence:.2f}',
                'gesture': gesture,
                'confidence': confidence,
                'required_confidence': required_confidence
            }

        # Debouncing - prevent rapid repeated actions
        current_time = time.time()
        if self.last_action_time:
            time_since_last = current_time - self.last_action_time
            if time_since_last < self.debounce_time:
                return {
                    'status': 'debounced',
                    'reason': f'Too soon after last action ({time_since_last:.1f}s)',
                    'wait_time': self.debounce_time - time_since_last
                }

        self.last_action_time = current_time

        # Create action log entry
        action_log = {
            'timestamp': datetime.now().isoformat(),
            'gesture': gesture,
            'confidence': confidence,
            'action': gesture_info['action'],
            'priority': gesture_info['priority']
        }
        self.action_history.append(action_log)

        # Return successful action
        return {
            'status': 'success',
            'action': gesture_info['action'],
            'description': gesture_info['description'],
            'medical_use': gesture_info['medical_use'],
            'icon': gesture_info['icon'],
            'priority': gesture_info['priority'],
            'confidence': confidence,
            'timestamp': action_log['timestamp'],
            'alert_level': gesture_info.get('alert_level', None)
        }

    def get_action_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get recent action history"""
        return self.action_history[-limit:]

    def clear_history(self):
        """Clear action history"""
        self.action_history = []
        print(" ✓ Action history cleared")

    def get_statistics(self) -> Dict[str, Any]:
        """Get usage statistics"""
        if not self.action_history:
            return {'total_actions': 0}

        # Count actions by priority
        priority_counts = {}
        action_counts = {}

        for entry in self.action_history:
            priority = entry['priority']
            action = entry['action']

            priority_counts[priority] = priority_counts.get(priority, 0) + 1
            action_counts[action] = action_counts.get(action, 0) + 1

        # Get most common action
        most_common = max(action_counts.items(), key=lambda x: x[1])

        return {
            'total_actions': len(self.action_history),
            'priority_breakdown': priority_counts,
            'action_breakdown': action_counts,
            'most_common_action': most_common[0],
            'most_common_count': most_common[1],
            'first_action_time': self.action_history[0]['timestamp'],
            'last_action_time': self.action_history[-1]['timestamp']
        }


# Save the handler class to a file
handler_code = '''import json
import time
from datetime import datetime
from typing import Dict, Any, Optional, List

class GestureActionHandler:
    """Handles gesture-to-action mapping for hospital system"""

    def __init__(self, mapping_file='config/medical_gesture_mapping.json'):
        with open(mapping_file, 'r', encoding='utf-8') as f:
            self.gesture_map = json.load(f)
        self.action_history = []
        self.last_action_time = None
        self.debounce_time = 1.0

    def get_action(self, gesture: str, confidence: float) -> Optional[Dict[str, Any]]:
        thresholds = {
            'critical': 0.85,
            'high': 0.75,
            'medium': 0.65,
            'low': 0.55
        }

        if gesture not in self.gesture_map:
            return {'status': 'unknown', 'reason': f'Gesture "{gesture}" not in mapping'}

        gesture_info = self.gesture_map[gesture]
        required_confidence = thresholds.get(gesture_info['priority'], 0.70)

        if confidence < required_confidence:
            return {'status': 'rejected', 'reason': 'Low confidence'}

        current_time = time.time()
        if self.last_action_time and (current_time - self.last_action_time < self.debounce_time):
            return {'status': 'debounced', 'reason': 'Too soon'}

        self.last_action_time = current_time
        self.action_history.append({
            'timestamp': datetime.now().isoformat(),
            'gesture': gesture,
            'confidence': confidence,
            'action': gesture_info['action'],
            'priority': gesture_info['priority']
        })

        return {
            'status': 'success',
            'action': gesture_info['action'],
            'description': gesture_info['description'],
            'medical_use': gesture_info['medical_use'],
            'icon': gesture_info['icon'],
            'priority': gesture_info['priority'],
            'confidence': confidence,
            'alert_level': gesture_info.get('alert_level', None)
        }

    def get_action_history(self, limit: int = 10):
        return self.action_history[-limit:]

    def clear_history(self):
        self.action_history = []
'''

with open('gesture_action_handler.py', 'w', encoding='utf-8') as f:
    f.write(handler_code)

print("\n ✓ Gesture Action Handler class created!")
print(" ✓ Saved to: gesture_action_handler.py")

# Test the handler
print("\n" + "="*80)
print(" TESTING HANDLER")
print("="*80)

handler = GestureActionHandler()

# Test different gestures
test_cases = [
    ("train_val_palm", 0.92, "High confidence emergency"),
    ("train_val_like", 0.78, "Confirmation gesture"),
    ("train_val_ok", 0.60, "Low confidence but acceptable"),
    ("train_val_palm", 0.50, "Too low confidence for critical"),
]

for gesture, confidence, description in test_cases:
    result = handler.get_action(gesture, confidence)
    print(f"\n Test: {description}")
    print(f"   Gesture: {gesture} (confidence: {confidence:.2f})")
    print(f"   Result: {result['status']}")
    if result['status'] == 'success':
        print(f"   Action: {result['action']} - {result['description']}")
        print(f"   Priority: {result['priority']} {result['icon']}")
    else:
        print(f"   Reason: {result.get('reason', 'N/A')}")

# Show statistics
print("\n" + "="*80)
print(" HANDLER STATISTICS")
print("="*80)
stats = handler.get_statistics()
print(f"\n Total actions processed: {stats['total_actions']}")
if stats['total_actions'] > 0:
    print(f" Most common action: {stats['most_common_action']} ({stats['most_common_count']} times)")

print("\n" + "="*80)
print("  ALL DONE!")
print("="*80)

